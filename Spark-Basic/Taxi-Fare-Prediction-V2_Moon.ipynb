{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd788a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6128ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 21:33:48 WARN Utils: Your hostname, Moon-2.local resolves to a loopback address: 127.0.0.1; using 192.168.0.4 instead (on interface en0)\n",
      "22/10/06 21:33:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 21:33:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/06 21:33:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "MAX_MEMORY = \"6g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediction\")\\\n",
    "        .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b459e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip_files = \"/Users/sig6774/Desktop/Data_Engineering/data-engineering-main/01-spark/data/tripdata_2021_1-7.csv\"\n",
    "trips_df = spark.read.csv(f\"file:///{trip_files}\",inferSchema=True, header=True)\n",
    "# 가지고 온 csv데이터를 spark의 df로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83ca6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d04b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql에서 사용하기 위해 tempview 생성 \n",
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21974a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치를 제거하고 가져옴 \n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count, \n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime),'EEEE') as day_of_week,\n",
    "    total_amount\n",
    "FROM \n",
    "    trips\n",
    "WHERE \n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0 \n",
    "    AND trip_distance > 0 \n",
    "    AND trip_distance < 500 \n",
    "    AND passenger_count < 4 \n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\"\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8849d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|            1.0|               142|                 43|          2.1|          0|     Friday|        11.8|\n",
      "|            1.0|               238|                151|          0.2|          0|     Friday|         4.3|\n",
      "|            1.0|               132|                165|         14.7|          0|     Friday|       51.95|\n",
      "|            0.0|               138|                132|         10.6|          0|     Friday|       36.35|\n",
      "|            1.0|                68|                 33|         4.94|          0|     Friday|       24.36|\n",
      "|            1.0|               224|                 68|          1.6|          0|     Friday|       14.15|\n",
      "|            1.0|                95|                157|          4.1|          0|     Friday|        17.3|\n",
      "|            1.0|                90|                 40|          5.7|          0|     Friday|        21.8|\n",
      "|            1.0|                97|                129|          9.1|          0|     Friday|        28.8|\n",
      "|            2.0|               263|                142|          2.7|          0|     Friday|       18.95|\n",
      "|            3.0|               164|                255|         6.11|          0|     Friday|        24.3|\n",
      "|            2.0|               255|                 80|         1.21|          0|     Friday|       10.79|\n",
      "|            2.0|               138|                166|          7.4|          0|     Friday|       33.92|\n",
      "|            1.0|               236|                237|         1.01|          0|     Friday|        10.3|\n",
      "|            1.0|               142|                239|         0.73|          0|     Friday|       12.09|\n",
      "|            1.0|               238|                166|         1.17|          0|     Friday|       12.36|\n",
      "|            1.0|               239|                238|         0.78|          0|     Friday|        9.96|\n",
      "|            2.0|               151|                142|         1.66|          0|     Friday|        12.3|\n",
      "|            3.0|               239|                142|         0.93|          0|     Friday|         9.3|\n",
      "|            2.0|               238|                142|         1.16|          0|     Friday|       11.84|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b4e58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415d2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 분리 \n",
    "train_df, test_df = data_df.randomSplit([0.8,0.2], seed=410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "863d5ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/Users/sig6774/Desktop/Data_Engineering/data-engineering-main/01-spark/data/train already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 위의 내용을 다시 불러오기에는 시간이 오래 걸리므로 파일로 저장해놓음 \u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sig6774/Desktop/Data_Engineering/data-engineering-main/01-spark/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/readwriter.py:968\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/Users/sig6774/Desktop/Data_Engineering/data-engineering-main/01-spark/data/train already exists."
     ]
    }
   ],
   "source": [
    "# 위의 내용을 다시 불러오기에는 시간이 오래 걸리므로 파일로 저장해놓음 \n",
    "# data_dir = \"/Users/sig6774/Desktop/Data_Engineering/data-engineering-main/01-spark/data/\"\n",
    "# train_df.write.format(\"parquet\").save(f\"{data_dir}/train/\")\n",
    "# test_df.write.format(\"parquet\").save(f\"{data_dir}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.parquet(f\"{data_dir}/train/\")\n",
    "test_df = spark.read.parquet(f\"{data_dir}/test/\")\n",
    "# 데이터를 쉽게 불러올 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b07facff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb5ffd",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d0b8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category data는 전처리가 필요함 \n",
    "# string값을 가지고와서 그것을 one-hot encoding 진행 \n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "cat_feats = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "# 파이프라인을 통해서 데이터를 통과시키도록 진행할 예정 \n",
    "# 파이프라인은 여러가지 stage로 되어 있으므로 그 stage를 담는 배열 선언 \n",
    "stages = []\n",
    "\n",
    "for c in cat_feats:\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol=c+\"_idx\").setHandleInvalid(\"keep\")\n",
    "    # invalid한 값도 어떻게 처리할 지 정의 \n",
    "    onehot_encoder = OneHotEncoder(inputCols=[cat_indexer.getOutputCol()], outputCols=[c+\"_onehot\"])\n",
    "    stages += [cat_indexer, onehot_encoder]\n",
    "    # 인덱서와 인코더를 파이프라인의 stages에 넣어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70096d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_67ee8bc542be,\n",
       " OneHotEncoder_5de1bd64c8cf,\n",
       " StringIndexer_aac3c40678dd,\n",
       " OneHotEncoder_81230022837d,\n",
       " StringIndexer_0468179c12fd,\n",
       " OneHotEncoder_c33c169ea76a]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20734cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric은 vector assembler로 진행 \n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "num_feats = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"pickup_time\"\n",
    "]\n",
    "\n",
    "for n in num_feats:\n",
    "    num_assembler = VectorAssembler(inputCols=[n], outputCol=n+\"_vector\")\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=n + \"_scaled\")\n",
    "    stages += [num_assembler, num_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b874f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_67ee8bc542be,\n",
       " OneHotEncoder_5de1bd64c8cf,\n",
       " StringIndexer_aac3c40678dd,\n",
       " OneHotEncoder_81230022837d,\n",
       " StringIndexer_0468179c12fd,\n",
       " OneHotEncoder_c33c169ea76a,\n",
       " VectorAssembler_1005e359cf39,\n",
       " StandardScaler_ee25009722b0,\n",
       " VectorAssembler_d4bb05a8b57c,\n",
       " StandardScaler_c8c047add8c1,\n",
       " VectorAssembler_261159e30a6c,\n",
       " StandardScaler_20000c72f25d]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d16389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical과 numerical 데이터를 하나로 합치면 학습이 가능\n",
    "assembler_inputs = [c + \"_onehot\" for c in cat_feats] + [n + \"_scaled\" for n in num_feats] \n",
    "assembler_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1da0e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_67ee8bc542be,\n",
       " OneHotEncoder_5de1bd64c8cf,\n",
       " StringIndexer_aac3c40678dd,\n",
       " OneHotEncoder_81230022837d,\n",
       " StringIndexer_0468179c12fd,\n",
       " OneHotEncoder_c33c169ea76a,\n",
       " VectorAssembler_1005e359cf39,\n",
       " StandardScaler_ee25009722b0,\n",
       " VectorAssembler_d4bb05a8b57c,\n",
       " StandardScaler_c8c047add8c1,\n",
       " VectorAssembler_261159e30a6c,\n",
       " StandardScaler_20000c72f25d,\n",
       " VectorAssembler_64b671e3f798]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"feature_vector\")\n",
    "stages += [assembler]\n",
    "# 마지막에 assembler 넣어줘야함 \n",
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7d653",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90b5cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "transform_stages = stages \n",
    "pipeline = Pipeline(stages=transform_stages)\n",
    "fitted_transformer = pipeline.fit(train_df)\n",
    "# 정의한 파이프라인에 데이터를 넣어줘서 일련의 과정을 진행 \n",
    "# pipeline 이거 하나의 함수같네 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04431b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrain_df = fitted_transformer.transform(train_df)\n",
    "# transform을 통해 학습이 가능한 상태로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c5a3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(\n",
    "        maxIter=5,\n",
    "        solver=\"normal\",\n",
    "        labelCol=\"total_amount\",\n",
    "        featuresCol=\"feature_vector\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95bd90d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 22:01:39 WARN Instrumentation: [e65b71d2] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 22:01:43 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/06 22:01:43 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 22:01:54 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "22/10/06 22:01:54 WARN Instrumentation: [e65b71d2] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/10/06 22:01:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/06 22:01:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6306b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = fitted_transformer.transform(test_df)\n",
    "# transform을 통해 테스트 가능한 상태로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b609a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+----------------------+-------------------------+-----------------------+--------------------------+---------------+------------------+----------------------+----------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|pickup_location_id_idx|pickup_location_id_onehot|dropoff_location_id_idx|dropoff_location_id_onehot|day_of_week_idx|day_of_week_onehot|passenger_count_vector|passenger_count_scaled|trip_distance_vector|trip_distance_scaled|pickup_time_vector|  pickup_time_scaled|      feature_vector|        prediction|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+----------------------+-------------------------+-----------------------+--------------------------+---------------+------------------+----------------------+----------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------------+\n",
      "|            0.0|                 4|                  4|          0.2|          0|  Wednesday|       74.75|                  62.0|         (263,[62],[1.0])|                   49.0|          (261,[49],[1.0])|            2.0|     (7,[2],[1.0])|                 [0.0]|                 [0.0]|               [0.2]|[0.05229544817812...|             [0.0]|               [0.0]|(534,[62,312,526,...|10.929842589879033|\n",
      "|            0.0|                 4|                 75|          5.3|         13|   Thursday|        22.8|                  62.0|         (263,[62],[1.0])|                   19.0|          (261,[19],[1.0])|            1.0|     (7,[1],[1.0])|                 [0.0]|                 [0.0]|               [5.3]|[1.3858293767203846]|            [13.0]|[2.5398325026854423]|(534,[62,282,525,...|23.410668178489793|\n",
      "|            0.0|                 4|                 79|          0.3|         23|  Wednesday|         7.3|                  62.0|         (263,[62],[1.0])|                   18.0|          (261,[18],[1.0])|            2.0|     (7,[2],[1.0])|                 [0.0]|                 [0.0]|               [0.3]|[0.07844317226719...|            [23.0]| [4.493549812443475]|(534,[62,281,526,...|12.459712222315154|\n",
      "|            0.0|                 4|                 90|          1.9|          1|     Sunday|        12.8|                  62.0|         (263,[62],[1.0])|                   28.0|          (261,[28],[1.0])|            6.0|     (7,[6],[1.0])|                 [0.0]|                 [0.0]|               [1.9]|[0.49680675769221...|             [1.0]|[0.19537173097580...|(534,[62,291,530,...|13.630621874882666|\n",
      "|            0.0|                 4|                170|          1.9|          5|  Wednesday|       14.15|                  62.0|         (263,[62],[1.0])|                    4.0|           (261,[4],[1.0])|            2.0|     (7,[2],[1.0])|                 [0.0]|                 [0.0]|               [1.9]|[0.49680675769221...|             [5.0]|[0.9768586548790164]|(534,[62,267,526,...|15.017208062658916|\n",
      "|            0.0|                 4|                249|          1.7|         19|   Saturday|       14.15|                  62.0|         (263,[62],[1.0])|                   22.0|          (261,[22],[1.0])|            4.0|     (7,[4],[1.0])|                 [0.0]|                 [0.0]|               [1.7]|[0.44451130951408...|            [19.0]|[3.7120628885402622]|(534,[62,285,528,...|14.880340915703279|\n",
      "|            0.0|                 7|                 48|          5.0|         13|   Saturday|        26.3|                  63.0|         (263,[63],[1.0])|                   10.0|          (261,[10],[1.0])|            4.0|     (7,[4],[1.0])|                 [0.0]|                 [0.0]|               [5.0]|[1.3073862044531932]|            [13.0]|[2.5398325026854423]|(534,[63,273,528,...|20.454820350080986|\n",
      "|            0.0|                 7|                100|          4.9|          7|   Thursday|       24.35|                  63.0|         (263,[63],[1.0])|                   30.0|          (261,[30],[1.0])|            1.0|     (7,[1],[1.0])|                 [0.0]|                 [0.0]|               [4.9]|[1.2812384803641292]|             [7.0]| [1.367602116830623]|(534,[63,293,525,...| 21.02798377810661|\n",
      "|            0.0|                 7|                170|          3.3|          8|     Monday|        18.3|                  63.0|         (263,[63],[1.0])|                    4.0|           (261,[4],[1.0])|            5.0|     (7,[5],[1.0])|                 [0.0]|                 [0.0]|               [3.3]|[0.8628748949391074]|             [8.0]|[1.5629738478064261]|(534,[63,267,529,...|16.094085346996486|\n",
      "|            0.0|                13|                 50|          4.7|         12|     Monday|        26.0|                  47.0|         (263,[47],[1.0])|                   35.0|          (261,[35],[1.0])|            5.0|     (7,[5],[1.0])|                 [0.0]|                 [0.0]|               [4.7]|[1.2289430321860015]|            [12.0]| [2.344460771709639]|(534,[47,298,529,...| 22.52476745896286|\n",
      "|            0.0|                13|                 68|          3.7|         16|    Tuesday|        22.3|                  47.0|         (263,[47],[1.0])|                   14.0|          (261,[14],[1.0])|            3.0|     (7,[3],[1.0])|                 [0.0]|                 [0.0]|               [3.7]|[0.9674657912953629]|            [16.0]|[3.1259476956128522]|(534,[47,277,527,...|20.740580902809256|\n",
      "|            0.0|                13|                 87|          1.3|         16|     Friday|        19.3|                  47.0|         (263,[47],[1.0])|                   46.0|          (261,[46],[1.0])|            0.0|     (7,[0],[1.0])|                 [0.0]|                 [0.0]|               [1.3]|[0.3399204131578302]|            [16.0]|[3.1259476956128522]|(534,[47,309,524,...|16.200784676243167|\n",
      "|            0.0|                13|                 90|          2.7|          9|     Monday|       16.45|                  47.0|         (263,[47],[1.0])|                   28.0|          (261,[28],[1.0])|            5.0|     (7,[5],[1.0])|                 [0.0]|                 [0.0]|               [2.7]|[0.7059885504047243]|             [9.0]|[1.7583455787822293]|(534,[47,291,529,...|17.176876010784447|\n",
      "|            0.0|                13|                100|          4.4|          6|    Tuesday|       21.62|                  47.0|         (263,[47],[1.0])|                   30.0|          (261,[30],[1.0])|            3.0|     (7,[3],[1.0])|                 [0.0]|                 [0.0]|               [4.4]|  [1.15049985991881]|             [6.0]|[1.1722303858548195]|(534,[47,293,527,...|21.915960396934565|\n",
      "|            0.0|                13|                100|          6.3|         15|     Sunday|       29.15|                  47.0|         (263,[47],[1.0])|                   30.0|          (261,[30],[1.0])|            6.0|     (7,[6],[1.0])|                 [0.0]|                 [0.0]|               [6.3]|[1.6473066176110231]|            [15.0]| [2.930575964637049]|(534,[47,293,530,...|26.075627449588367|\n",
      "|            0.0|                13|                142|          4.4|         16|    Tuesday|       22.55|                  47.0|         (263,[47],[1.0])|                    6.0|           (261,[6],[1.0])|            3.0|     (7,[3],[1.0])|                 [0.0]|                 [0.0]|               [4.4]|  [1.15049985991881]|            [16.0]|[3.1259476956128522]|(534,[47,269,527,...|22.201693417337815|\n",
      "|            0.0|                13|                143|          4.8|          7|  Wednesday|        28.5|                  47.0|         (263,[47],[1.0])|                   23.0|          (261,[23],[1.0])|            2.0|     (7,[2],[1.0])|                 [0.0]|                 [0.0]|               [4.8]|[1.2550907562750653]|             [7.0]| [1.367602116830623]|(534,[47,286,526,...|23.200616020830815|\n",
      "|            0.0|                13|                144|          2.0|         19|  Wednesday|        13.8|                  47.0|         (263,[47],[1.0])|                   41.0|          (261,[41],[1.0])|            2.0|     (7,[2],[1.0])|                 [0.0]|                 [0.0]|               [2.0]|[0.5229544817812772]|            [19.0]|[3.7120628885402622]|(534,[47,304,526,...|17.982455745335585|\n",
      "|            0.0|                13|                161|          4.4|          7|   Thursday|        24.8|                  47.0|         (263,[47],[1.0])|                    3.0|           (261,[3],[1.0])|            1.0|     (7,[1],[1.0])|                 [0.0]|                 [0.0]|               [4.4]|  [1.15049985991881]|             [7.0]| [1.367602116830623]|(534,[47,266,525,...|21.934668490319453|\n",
      "|            0.0|                13|                162|          6.4|          7|     Monday|       27.35|                  47.0|         (263,[47],[1.0])|                    8.0|           (261,[8],[1.0])|            5.0|     (7,[5],[1.0])|                 [0.0]|                 [0.0]|               [6.4]|[1.6734543417000873]|             [7.0]| [1.367602116830623]|(534,[47,271,529,...| 26.21461039905876|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+----------------------+-------------------------+-----------------------+--------------------------+---------------+------------------+----------------------+----------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(vtest_df)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b62b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: double, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vector: vector, passenger_count_scaled: vector, trip_distance_vector: vector, trip_distance_scaled: vector, pickup_time_vector: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.cache()\n",
    "# 캐싱으로 조금 더 쉽게 쓸 수 있도록 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0afe4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+\n",
      "|trip_distance|day_of_week|total_amount|        prediction|\n",
      "+-------------+-----------+------------+------------------+\n",
      "|          0.2|  Wednesday|       74.75|10.929842589879033|\n",
      "|          5.3|   Thursday|        22.8|23.410668178489793|\n",
      "|          0.3|  Wednesday|         7.3|12.459712222315154|\n",
      "|          1.9|     Sunday|        12.8|13.630621874882666|\n",
      "|          1.9|  Wednesday|       14.15|15.017208062658916|\n",
      "|          1.7|   Saturday|       14.15|14.880340915703279|\n",
      "|          5.0|   Saturday|        26.3|20.454820350080986|\n",
      "|          4.9|   Thursday|       24.35| 21.02798377810661|\n",
      "|          3.3|     Monday|        18.3|16.094085346996486|\n",
      "|          4.7|     Monday|        26.0| 22.52476745896286|\n",
      "|          3.7|    Tuesday|        22.3|20.740580902809256|\n",
      "|          1.3|     Friday|        19.3|16.200784676243167|\n",
      "|          2.7|     Monday|       16.45|17.176876010784447|\n",
      "|          4.4|    Tuesday|       21.62|21.915960396934565|\n",
      "|          6.3|     Sunday|       29.15|26.075627449588367|\n",
      "|          4.4|    Tuesday|       22.55|22.201693417337815|\n",
      "|          4.8|  Wednesday|        28.5|23.200616020830815|\n",
      "|          2.0|  Wednesday|        13.8|17.982455745335585|\n",
      "|          4.4|   Thursday|        24.8|21.934668490319453|\n",
      "|          6.4|     Monday|       27.35| 26.21461039905876|\n",
      "+-------------+-----------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pred.select([\"trip_distance\", \"day_of_week\", \"total_amount\",\"prediction\" ]).show()\n",
    "# 원하는 컬럼만 보면서 예측 결과 확이 ㄴ가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f1aad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.888596638783108"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7598f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794118428724808"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
